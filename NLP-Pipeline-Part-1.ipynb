{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "raw_mimetype": "text/html"
   },
   "source": [
    "\n",
    "<html>\n",
    "<body>\n",
    "\n",
    "<b><p>\n",
    "Natural Language Processing.\n",
    "</p></b>\n",
    "\n",
    "<p>\n",
    "Zeros and Ones is all what the computer understands. Computers are able to outperform humans in numbers and calculations and now with the advent of Machine Learning and Neural Networks, also in finding patterns in large amounts of data which humans cannot even dream of recognising and processing without any aid.</p>\n",
    "    \n",
    "    \n",
    "<p>Alexaaa! \"Play khalid's song `Young Dumb and Broke.`\"</p>\n",
    "<p>Siri! \"Set an alarm for 5 am, I want to try to waking up early tomorrow\"</p>\n",
    "<p> Google! \"Order a tub of Death by chocolate for me\". I am kidding, Google assistant can't do that YET. But it can surely give you some restaurant suggestions along with contact details to choose from. </p>\n",
    "\n",
    "<p>\n",
    "How are these assistants able to process these Natural Language sentences, if they only  understand numbers? Pause reading this article, and try answering this question.\n",
    "</p>\n",
    "\n",
    "<p>What if, somehow we convert these words into numbers :) Well, That's what NLP is about.</p> \n",
    "\n",
    "<p> One of the definition on the internet, \"Natural Language Processing, usually shortened as NLP, is a branch of artificial intelligence that deals with the interaction between computers and humans using the Natural Language. The Ultimate objective of NLP is to read, decipher, understand, and make sense of the human languages in a manner that is valuable. Most NLP techniques rely on Machine learning and Neural Networks to derive meaning from human languages. \" </p> \n",
    "    \n",
    "<p> This article aims at teaching you the basics of NLP step by step along with some basic coding practises in Python. And also, some surprise tools by IBM which make your extensive NLP tasks much simpler. </p> \n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Travel back in time when you were a small kid learning alphabets. Next you learned how to make words with those alphabets, and then you start making sentences with those words. One day you start making use of those sentences to have a conversation to convey your feelings. \n",
    "\n",
    "Here's the first excercise for you.\n",
    "\n",
    "Below is the paragraph on Khalid singer taken from wikipedia. Take a notebook and pen, and as you read\n",
    "\n",
    "<ol>\n",
    "  <li> Pick Keywords from every sentence.</li>\n",
    "  <li> Tag approriate Parts of Speech to every Keyword</li>\n",
    "  <li> Classify keywords(if possible) into categories like person, location, organisation, date, etc.</li>\n",
    "</ol> \n",
    "\n",
    "<p style=\"color:green\">Khalid Donnel Robinson (born February 11, 1998) is an American singer and songwriter. He is signed to Right Hand Music Group and RCA Records. His debut single, \"Location\", was released in July 2016 and peaked at number 16 on the US Billboard Hot 100 chart and was later certified quadruple platinum by the Recording Industry Association of America (RIAA). His debut studio album, American Teen, was released on March 3, 2017. Since then he has achieved several top 10 hits, a top-ten charting EP, a number one album and six Grammy nominations.</p>\n",
    "\n",
    "\n",
    "Now, Let's see how we teach machine to process this paragraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://en.wikipedia.org/wiki/Khalid_(singer)\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x122e5ebd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://en.wikipedia.org/wiki/Khalid_(singer)', width=800, height=450)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Steps are similar to the exercise you did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Sentence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Segmentation also known as Sentence Boundary Detection is the first step in the NLP pipeline is to break down the  paragraph/text into sentences. It becomes much easier to understand the sentiment and structure of the sentence than to understand the entire paragraph all together. Just like we read a novel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After breaking down the Document in sentences. We further break the sentence into tokens. Tokens are the different words in the sentence. This process of breaking a sentence into different words is called Tokenization. We’ll just split apart words whenever there’s a space between them. And we’ll also treat punctuation marks as separate tokens since punctuation also has meaning. For example: \n",
    "\n",
    "<p style=\"color:green\">Khalid Donnel Robinson (born February 11, 1998) is an American singer and songwriter.</p> \n",
    "\n",
    "Tokenising them would result in...\n",
    "Just see for yourself. Run the next Cell :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Khalid\n",
      "2. Donnel\n",
      "3. Robinson\n",
      "4. (\n",
      "5. born\n",
      "6. February\n",
      "7. 11\n",
      "8. ,\n",
      "9. 1998\n",
      "10. )\n",
      "11. is\n",
      "12. an\n",
      "13. American\n",
      "14. singer\n",
      "15. and\n",
      "16. songwriter\n",
      "17. .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Khalid Donnel Robinson (born February 11, 1998) is an American singer and songwriter.\")\n",
    "counter = 1\n",
    "for token in doc:\n",
    "    # Print the token and its part-of-speech tag\n",
    "    print(str(counter) +\". \" +token.text)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Predicting Parts of Speech for Each Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It really important to understand the structure of the sentence. Once you start parts of speech tagging it tells about, what is the role played by a word in a sentence. It becomes easier to understand the context of the sentence after POS Tagging.\n",
    "Some of the common parts of speech in English are Noun, Pronoun, Adjective, Verb, Adverb, etc. POS tagging is the task of automatically assigning POS tags to all the words of a sentence.\n",
    "\n",
    "Here's the code you can use to automate the POS Tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Khalid --> PROPN\n",
      "2. Donnel --> PROPN\n",
      "3. Robinson --> PROPN\n",
      "4. ( --> PUNCT\n",
      "5. born --> VERB\n",
      "6. February --> PROPN\n",
      "7. 11 --> NUM\n",
      "8. , --> PUNCT\n",
      "9. 1998 --> NUM\n",
      "10. ) --> PUNCT\n",
      "11. is --> VERB\n",
      "12. an --> DET\n",
      "13. American --> ADJ\n",
      "14. singer --> NOUN\n",
      "15. and --> CCONJ\n",
      "16. songwriter --> NOUN\n",
      "17. . --> PUNCT\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "for token in doc:\n",
    "    # Print the token and its part-of-speech tag\n",
    "    print(str(counter) +\". \" + token.text, \"-->\", token.pos_)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coordinating conjunction'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you don't understand any of the POS tagging, you can use the explain feature of Spacy\n",
    "spacy.explain(\"CCONJ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Text Lemmatization - Needs Editing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is the process of converting a word to its base form. The difference between stemming and lemmatization is, lemmatization considers the context and converts the word to its meaningful base form, whereas stemming just removes the last few characters, often leading to incorrect meanings and spelling errors.\n",
    "\n",
    "For example, lemmatization would correctly identify the base form of ‘caring’ to ‘care’, whereas, stemming would cutoff the ‘ing’ part and convert it to car.\n",
    "\n",
    "‘Caring’ -> Lemmatization -> ‘Care’\n",
    "‘Caring’ -> Stemming -> ‘Car’\n",
    "\n",
    "Also, sometimes, the same word can have multiple different ‘lemma’s. So, based on the context it’s used, you should identify the ‘part-of-speech’ (POS) tag for the word in that specific context and extract the appropriate lemma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on -PRON- foot for good'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "doc = nlp(sentence)\n",
    "\" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities are the words or groups of words that represent information about common things such as persons, locations, organizations, etc. These entities have proper names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Khalid Donnel Robinson: PERSON\n",
      "February 11, 1998: DATE\n",
      "American: NORP\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text + \": \"+ent.label_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalities or religious or political groups'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you didn't understand what does `NORP` means? You are not alone!\n",
    "\n",
    "spacy.explain(\"NORP\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBM Watson Natural Language Understanding\n",
    "You don't have to code anything. Just give the URL or the text you want to analyse in the below code. And IBM Watson Natural Language Understanding does all the work for you. On a single click, it can give you \n",
    "`Categories, Concepts, Keywords, Entities, Emotions, Semantic Roles, Relation and Metadata` in the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to create service on IBM Cloud: \n",
    "* Create an instance of the service:\n",
    "* Go to the Natural Language Understanding page in the IBM Cloud catalog.\n",
    "* Sign up for a free IBM Cloud account or log in.\n",
    "* Click Create.\n",
    "* Copy the credentials to authenticate to your service instance:\n",
    "* On the Manage page, click Show Credentials.\n",
    "* Copy the API Key and URL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"usage\": {\n",
      "    \"text_units\": 2,\n",
      "    \"text_characters\": 14252,\n",
      "    \"features\": 3\n",
      "  },\n",
      "  \"retrieved_url\": \"https://en.wikipedia.org/wiki/Khalid_(singer)\",\n",
      "  \"language\": \"en\",\n",
      "  \"keywords\": [\n",
      "    {\n",
      "      \"text\": \"Khalid Donnel Robinson\",\n",
      "      \"sentiment\": {\n",
      "        \"score\": 0,\n",
      "        \"label\": \"neutral\"\n",
      "      },\n",
      "      \"relevance\": 0.862562,\n",
      "      \"emotion\": {\n",
      "        \"sadness\": 0.165629,\n",
      "        \"joy\": 0.435899,\n",
      "        \"fear\": 0.021146,\n",
      "        \"disgust\": 0.060469,\n",
      "        \"anger\": 0.125631\n",
      "      },\n",
      "      \"count\": 2\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Songs chart\",\n",
      "      \"sentiment\": {\n",
      "        \"score\": 0,\n",
      "        \"label\": \"neutral\"\n",
      "      },\n",
      "      \"relevance\": 0.621858,\n",
      "      \"emotion\": {\n",
      "        \"sadness\": 0.074985,\n",
      "        \"joy\": 0.730455,\n",
      "        \"fear\": 0.006682,\n",
      "        \"disgust\": 0.004955,\n",
      "        \"anger\": 0.036803\n",
      "      },\n",
      "      \"count\": 3\n",
      "    }\n",
      "  ],\n",
      "  \"concepts\": [\n",
      "    {\n",
      "      \"text\": \"Billboard charts\",\n",
      "      \"relevance\": 0.946499,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/Billboard_charts\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Billboard Hot 100\",\n",
      "      \"relevance\": 0.808301,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/Billboard_Hot_100\"\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Billboard\",\n",
      "      \"relevance\": 0.691226,\n",
      "      \"dbpedia_resource\": \"http://dbpedia.org/resource/Billboard_(magazine)\"\n",
      "    }\n",
      "  ],\n",
      "  \"categories\": [\n",
      "    {\n",
      "      \"score\": 0.997337,\n",
      "      \"label\": \"/art and entertainment/music/recording industry/music awards\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, CategoriesOptions, ConceptsOptions, KeywordsOptions\n",
    "\n",
    "authenticator = IAMAuthenticator('-f_f6NG-Z_lS_-wjDjM490vnWsSPDa69U_UZLeVX8Ylx')\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "    version='2019-07-12',\n",
    "    authenticator=authenticator\n",
    ")\n",
    "\n",
    "natural_language_understanding.set_service_url('https://api.us-south.natural-language-understanding.watson.cloud.ibm.com/instances/8d1a58d6-156e-416c-ae94-5a0f579391eb')\n",
    "\n",
    "response = natural_language_understanding.analyze(\n",
    "    url='https://en.wikipedia.org/wiki/Khalid_(singer)',\n",
    "    features=Features(categories=CategoriesOptions(limit=3),concepts=ConceptsOptions(limit=3),keywords=KeywordsOptions(sentiment=True,emotion=True,limit=2))).get_result()\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.713px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
